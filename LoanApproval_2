#-----------------------------------------------------------------------------------------#
იგივე კოდი დამატებული სკალირების ეტაპი, როგორც მონაცემების დამუშავების ეტაპზე 
ისე ახალ მონაცემების შეყვანის დროსაც 
#-----------------------------------------------------------------------------------------#
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
#---------------------------------------#
# Data load
drive.mount('/content/drive')
data = pd.read_csv("LoanApprovalPrediction.csv")
df = data.copy()
# Count categorical columns
obj = (df.dtypes == 'object')
print("Categorical variables:", len(list(obj[obj].index)))
# Drop Loan_ID if exists
if 'Loan_ID' in df.columns:
    df.drop(['Loan_ID'], axis=1, inplace=True)
# Visualize unique values for categorical columns
obj = (df.dtypes == 'object')
object_cols = list(obj[obj].index)
plt.figure(figsize=(18, 36))
index = 1
for col in object_cols:
    y = df[col].value_counts()
    plt.subplot(11, 4, index)
    plt.xticks(rotation=90)
    sns.barplot(x=list(y.index), y=y)
    index += 1
plt.show()
# Label Encoding with saving encoders
from sklearn import preprocessing
encoders = {}
for col in object_cols:
    le = preprocessing.LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    encoders[col] = le
# Fill missing values with mean
for col in df.columns:
    df[col] = df[col].fillna(df[col].mean())
# Correlation Heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(df.corr(), cmap='BrBG', annot=True, fmt=".2f", linewidths=2)
plt.show()
# Split data
from sklearn.model_selection import train_test_split

X = df.drop(['Loan_Status'], axis=1)
Y = df['Loan_Status']

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.4, random_state=1
)
# Scaling
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Model training and evaluation
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

models = [
    RandomForestClassifier(n_estimators=7, criterion='entropy', random_state=7),
    KNeighborsClassifier(n_neighbors=3),
    SVC(),
    LogisticRegression()
]

best_model = None
best_score = 0

print("\n--- Accuracy on Training Set ---")
for clf in models:
    clf.fit(X_train_scaled, Y_train)
    Y_pred = clf.predict(X_train_scaled)
    score = metrics.accuracy_score(Y_train, Y_pred)
    print(f"{clf.__class__.__name__}: {score*100:.2f}%")
    if score > best_score:
        best_score = score
        best_model = clf

print("\n--- Accuracy on Test Set ---")
for clf in models:
    clf.fit(X_train_scaled, Y_train)
    Y_pred = clf.predict(X_test_scaled)
    score = metrics.accuracy_score(Y_test, Y_pred)
    print(f"{clf.__class__.__name__}: {score*100:.2f}%")

print("\nBest model based on training set:", best_model.__class__.__name__)
# prediction on new data
new_data = {
    'Gender': 'Male',
    'Married': 'Yes',
    'Dependents': '0',
    'Education': 'Graduate',
    'Self_Employed': 'No',
    'ApplicantIncome': 5000,
    'CoapplicantIncome': 0,
    'LoanAmount': 150,
    'Loan_Amount_Term': 360,
    'Credit_History': 1.0,
    'Property_Area': 'Urban'
}

new_df = pd.DataFrame([new_data])

# Ensure same column order as training data
new_df = new_df[X_train.columns]

from sklearn import preprocessing 
# label_encoder object knows how 
# to understand word labels.
label_encoder = preprocessing.LabelEncoder()
obj = (new_df.dtypes == 'object')
for col in list(obj[obj].index):
  new_df[col] = label_encoder.fit_transform(new_df[col])
# 5. სკალირება იმავე სკალერით, რაც ტრენინგზე გაქვს
new_df_scaled = scaler.transform(new_df)

# 6. პროგნოზი
prediction = best_model.predict(new_df_scaled)[0]

status_map = {1: "Approved", 0: "Rejected"}
print("\nPrediction for new data:", status_map.get(prediction, prediction))
