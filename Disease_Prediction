Step 1 : Import Libraries   --------------------------------------------------------------
import numpy as np
import pandas as pd
from scipy.stats import mode
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
--------------------------------------------------------------------------------------------
Step 2 :   Import Data    ------------------------------------------------------------------
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv("Path")
--------------------------------------------------------------------------------------------
Step 3 :   Overview    ---------------------------------------------------------------------
df.columns
df.dtypes
df['disease'].values  >>> Target Column
df['disease'].nunique()
df['disease'].value_counts(sort = False)
df.isnull().sum()
--------------------------------------------------------------------------------------------
Step 4 :   Target Column Encoding    -------------------------------------------------------
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df["disease"] = encoder.fit_transform(df["disease"])
--------------------------------------------------------------------------------------------
Step 5 :   Define x And y    ---------------------------------------------------------------
X = df.iloc[:, :-1]
y = df.iloc[:, -1]
---- visualize distribution 
plt.figure(figsize=(10, 5))
sns.countplot(x=y)
plt.title("Disease Class Distribution Before Resampling")
plt.xticks(rotation=90)
plt.show()
--------------------------------------------------------------------------------------------
Step 6 :   Handling Imbalances    ----------------------------------------------------------
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
import pandas as pd
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)
print("Resampled Class Distribution:\n", pd.Series(y_resampled).value_counts())
--------------------------------------------------------------------------------------------
Step 7 :   Voting Classifier    ------------------------------------------------------------
### than we will try cross validation method
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Define classifiers
clf_1 = LogisticRegression()
clf_2 = XGBClassifier()
clf_3 = SVC(probability=True)  # Important if you later use soft voting

# Voting classifier
voter = VotingClassifier(estimators=[
    ('lr', clf_1),
    ('xgb', clf_2),
    ('svc', clf_3)
], voting='hard')  # or 'soft' if you prefer probabilities

# Fit individual classifiers
clf_1.fit(X_train, y_train)
clf_2.fit(X_train, y_train)
clf_3.fit(X_train, y_train)

# Fit voting classifier
voter.fit(X_train, y_train)

# Predictions and accuracy
models = {'Logistic Regression': clf_1,
          'XGBoost': clf_2,
          'SVC': clf_3,
          'Voting Classifier': voter}

print("üîç Accuracy Scores:")
for name, model in models.items():
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    train_acc = accuracy_score(y_train, train_pred)
    test_acc = accuracy_score(y_test, test_pred)
    print(f"{name} - Train: {train_acc:.3f}, Test: {test_acc:.3f}")
--------------------------------------------------------------------------------------------
Step 8 :   Cross Validation    -------------------------------------------------------------
clf1 = LogisticRegression()
clf2 = RandomForestClassifier()
clf3 = GradientBoostingClassifier()
# Combine with voting
voting_clf = VotingClassifier(
    estimators=[('lr', clf1), ('rf', clf2), ('gb', clf3)],
    voting='soft'  # soft = use predicted probabilities, hard = majority vote
)

# Cross-validation on the combined model
scores = cross_val_score(voting_clf, X, y, cv=5)
print("VotingClassifier CV scores:", scores)
print("Mean score:", scores.mean())
üí° Key takeaway:
cross_val_score() is only for evaluation ‚Äî it doesn‚Äôt store trained models for later use.
If you want to predict on new data afterward, 
you must train the models again (or load from saved files) before predicting.
--------------------------------------------------------------------------------------------
Step 9 :   train (fit)    ------------------------------------------------------------------
# Final training on full training set
# -----------------------
clf1.fit(X_train, y_train)
clf2.fit(X_train, y_train)
clf3.fit(X_train, y_train)
 -----------------------
# Evaluate on hold-out test set
# -----------------------
test_score1 = clf1.score(X_test, y_test)
test_score2 = clf2.score(X_test, y_test)
test_score3 = clf3.score(X_test, y_test)
print("\nTest set accuracy:")
print(f"Model 1 (LR): {test_score1:.2f}")
print(f"Model 2 (RF): {test_score2:.2f}")
print(f"Model 3 (GB): {test_score3:.2f}")
--------------------------------------------------------------------------------------------
Step 10 :   Prediction Enter New_Data    ----------------------------------------------------
# -----------------------
# Predict for new patient
# -----------------------
new_data = pd.DataFrame([{
    'fever': 1,
    'headache': 0,
    'nausea': 1,
    'vomiting': 0,
    'fatigue': 1,
    'joint_pain': 0,
    'skin_rash': 0,
    'cough': 1,
    'weight_loss': 0,
    'yellow_eyes': 1
}])

pred1 = clf1.predict(new_data)[0]
pred2 = clf2.predict(new_data)[0]
pred3 = clf3.predict(new_data)[0]

print("\nPredictions for new patient:")
print("Model 1 Prediction (LR):", pred1)
print("Model 2 Prediction (RF):", pred2)
print("Model 3 Prediction (GB):", pred3)

# -----------------------
# Majority voting manually
# -----------------------
final_pred = mode([pred1, pred2, pred3], keepdims=False)[0]
print("\nFinal chosen prediction (majority vote):", final_pred)





















