Step 1 : Import Libraries   --------------------------------------------------------------
import numpy as np
import pandas as pd
from scipy.stats import mode
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
--------------------------------------------------------------------------------------------
Step 2 :   Import Data    ------------------------------------------------------------------
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv("Path")
--------------------------------------------------------------------------------------------
Step 3 :   Overview    ---------------------------------------------------------------------
df.columns
df.dtypes
df['disease'].values  >>> Target Column
df['disease'].nunique()
df['disease'].value_counts(sort = False)
df.isnull().sum()
--------------------------------------------------------------------------------------------
Step 4 :   Target Column Encoding    -------------------------------------------------------
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df["disease"] = encoder.fit_transform(df["disease"])
--------------------------------------------------------------------------------------------
Step 5 :   Define x And y    ---------------------------------------------------------------
X = df.iloc[:, :-1]
y = df.iloc[:, -1]
---- visualize distribution 
plt.figure(figsize=(10, 5))
sns.countplot(x=y)
plt.title("Disease Class Distribution Before Resampling")
plt.xticks(rotation=90)
plt.show()
--------------------------------------------------------------------------------------------
Step 6 :   Handling Imbalances    ----------------------------------------------------------
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
import pandas as pd
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)
print("Resampled Class Distribution:\n", pd.Series(y_resampled).value_counts())
--------------------------------------------------------------------------------------------
Step 7 :   Voting Classifier    ------------------------------------------------------------
### than we will try cross validation method
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Define classifiers
clf_1 = LogisticRegression()
clf_2 = XGBClassifier()
clf_3 = SVC(probability=True)  # Important if you later use soft voting

# Voting classifier
voter = VotingClassifier(estimators=[
    ('lr', clf_1),
    ('xgb', clf_2),
    ('svc', clf_3)
], voting='hard')  # or 'soft' if you prefer probabilities

# Fit individual classifiers
clf_1.fit(X_train, y_train)
clf_2.fit(X_train, y_train)
clf_3.fit(X_train, y_train)

# Fit voting classifier
voter.fit(X_train, y_train)

# Predictions and accuracy
models = {'Logistic Regression': clf_1,
          'XGBoost': clf_2,
          'SVC': clf_3,
          'Voting Classifier': voter}

print("üîç Accuracy Scores:")
for name, model in models.items():
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    train_acc = accuracy_score(y_train, train_pred)
    test_acc = accuracy_score(y_test, test_pred)
    print(f"{name} - Train: {train_acc:.3f}, Test: {test_acc:.3f}")
--------------------------------------------------------------------------------------------
Step 8 :   Cross Validation    -------------------------------------------------------------





















